{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplest model with one conv layer and 1 fully-connected hidden layer \n",
    "#### Same as v3\n",
    "#### Added test\n",
    "#### Visualization of loss and test curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_height = 480\n",
    "image_width = 720\n",
    "\n",
    "def load_data(test=False):\n",
    "    fname = 'test.csv' if test else 'FLIC_dataset.csv'\n",
    "    df = pd.read_csv(fname, nrows = 300)\n",
    "    del df['Unnamed: 0']\n",
    "    cols = df.columns[:-1]\n",
    "    y = df[cols]\n",
    "    \n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' ') / 255.0)\n",
    "    df = df.dropna()\n",
    "    X = np.vstack(df['Image'])\n",
    "    X = X.reshape(-1, image_height, image_width, 1)\n",
    "    \n",
    "    if not test:\n",
    "        y1 = y.ix[:,0:9] / 720.0\n",
    "        y2 = y.ix[:,9:] / 480.0\n",
    "        y = pd.concat([y1, y2], axis = 1)\n",
    "        X, y = shuffle(X, y)\n",
    "\n",
    "    else:\n",
    "        y = None\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 480, 720, 1)\n"
     ]
    }
   ],
   "source": [
    "x,y = load_data()\n",
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To evaluate how good a prediction is\n",
    "def eval_error(pred, ground_truth):\n",
    "    return np.sqrt(mean_squared_error(pred, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train has shape of:\n",
      "(240, 480, 720, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_valid, y_train,y_valid = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "print (\"x_train has shape of:\")\n",
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([Dimension(16), Dimension(2764800)])\n",
      "TensorShape([Dimension(60), Dimension(2764800)])\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------------------------------------------\n",
    "## Here is the start of the TF graph\n",
    "## -------------------------------------------------------------------------\n",
    "batch_size = 16\n",
    "image_height = 480\n",
    "image_width = 720\n",
    "num_channels = 1\n",
    "num_labels = 18\n",
    "\n",
    "deep_graph = tf.Graph()\n",
    "with deep_graph.as_default():\n",
    "\n",
    "    tf_valid_dataset = tf.constant(x_valid, dtype = tf.float32)\n",
    "    #tf_test_dataset = tf.constant(x_test, dtype = tf.float32) \n",
    "\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "        tf.float32, \n",
    "        shape = (batch_size, image_height, image_width, num_channels))\n",
    "\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, num_labels))\n",
    "\n",
    "    conv1_weight = tf.Variable(\n",
    "        tf.truncated_normal([5, 5, num_channels, 32], \n",
    "                            stddev = 0.1, seed = 0))\n",
    "\n",
    "    conv1_biases = tf.Variable(tf.zeros([32]))\n",
    "\n",
    "#     conv2_weights = tf.Variable(\n",
    "#             tf.truncated_normal([5, 5, 32, 64], \n",
    "#                                 stddev = 0.1, seed = 0, dtype = tf.float32))\n",
    "\n",
    "#     conv2_biases = tf.Variable(tf.constant(0.1, shape = [64]))\n",
    "\n",
    "    fc1_weights = tf.Variable(\n",
    "        tf.truncated_normal([image_height * image_width * 8 , num_labels], \n",
    "                            stddev = 0.1, seed = 0, dtype = tf.float32))\n",
    "\n",
    "    fc1_biases = tf.Variable(tf.constant(0.1, shape = [num_labels]))\n",
    "\n",
    "#     fc2_weights = tf.Variable(\n",
    "#         tf.truncated_normal([512, 512], \n",
    "#                             stddev = 0.1, seed = 0, dtype = tf.float32))\n",
    "\n",
    "#     fc2_biases = tf.Variable(tf.constant(0.1, shape = [512]))\n",
    "\n",
    "#     fc3_weights = tf.Variable(\n",
    "#         tf.truncated_normal([512, num_labels], stddev = 0.1, seed = 0, dtype = tf.float32))\n",
    "\n",
    "#     fc3_biases = tf.Variable(tf.constant(0.1, shape = [num_labels]))\n",
    "\n",
    "    def model(data, train = False):\n",
    "        conv1 = tf.nn.conv2d(data, conv1_weight, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "        relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n",
    "\n",
    "        pool1 = tf.nn.max_pool(relu1, ksize = [1, 2, 2, 1], \n",
    "                                strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "#         conv2 = tf.nn.conv2d(pool1, conv2_weights, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "#         relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "\n",
    "#         pool2 = tf.nn.max_pool(relu2, ksize = [1, 2, 2, 1],\n",
    "#                                 strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "        # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "        # fully connected layers.\n",
    "        pool_shape = pool1.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool1, [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "#         reshape = tf.Print(reshape, [reshape], \"reshape: \", summarize=10)\n",
    "        print (reshape.get_shape())\n",
    "        # Fully connecte layers\n",
    "        hidden_layer1 = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "        # For training data, add 0.5 dropout. \n",
    "        return hidden_layer1\n",
    "        \n",
    "#         if train:\n",
    "#             hidden_layer1 = tf.nn.dropout(hidden_layer1, 0.5, seed = 0)\n",
    "\n",
    "#         hidden_layer2 = tf.nn.relu(tf.matmul(hidden_layer1, fc2_weights) + fc2_biases)\n",
    "\n",
    "#         if train:\n",
    "#             hidden_layer2 = tf.nn.dropout(hidden_layer2, 0.5, seed = 0)\n",
    "\n",
    "#         return tf.matmul(hidden_layer2, fc3_weights) + fc3_biases\n",
    "\n",
    "    # Call the model() function to make train_prediction\n",
    "    train_prediction = model(tf_train_dataset, True)\n",
    "    valid_prediction = model(tf_valid_dataset)\n",
    "    # calculate loss by using train_prediction\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(train_prediction - tf_train_labels), 1))\n",
    "    # Add L2 regularization to loss\n",
    "#     loss += 1e-7 * (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "#             tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases) + \n",
    "#             tf.nn.l2_loss(fc3_weights) + tf.nn.l2_loss(fc3_biases)) \n",
    "\n",
    "    # Optimizer\n",
    "    global_step = tf.Variable(0, name = 'global_step',trainable = False)\n",
    "    starter_learning_rate = 0.001\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate,\n",
    "                                                global_step,\n",
    "                                                100000,\n",
    "                                                0.96,\n",
    "                                                staircase = True)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate, 0.95).minimize(loss, global_step = global_step)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running TF graph ... \n",
      "TF graph variables initialized ... \n",
      "(16, 18)\n",
      "Minibatch loss at step 0: 6075.998047\n",
      "Validation RMSE: 0.58837\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 2: 4.264675\n",
      "Validation RMSE: 0.53871\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 4: 4.943174\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 6: 5.284591\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 8: 4.706374\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 10: 5.685203\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 12: 4.745906\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 14: 5.656637\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 16: 4.264675\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 18: 4.943174\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 20: 5.284591\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 22: 4.721578\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 24: 5.685203\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 26: 4.745906\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 28: 5.656637\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 30: 4.264675\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 32: 4.943174\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 34: 5.284591\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 36: 4.721578\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 38: 5.685203\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 40: 4.745906\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 42: 5.656637\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 44: 4.264675\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 46: 4.943174\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 48: 5.284591\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 50: 4.721578\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 52: 5.685203\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 54: 4.745906\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 56: 5.656637\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 58: 4.264675\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 60: 4.943174\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 62: 5.284591\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 64: 4.721578\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 66: 5.685203\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 68: 4.745906\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 70: 5.656637\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 72: 4.264675\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 74: 4.943174\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 76: 5.284591\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 78: 4.721578\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 80: 5.685203\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 82: 4.745906\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 84: 5.656637\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 86: 4.264675\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 88: 4.943174\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 90: 5.284591\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 92: 4.721578\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 94: 5.685203\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 96: 4.745906\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 98: 5.656637\n",
      "Validation RMSE: 0.53872\n",
      "(16, 18)\n",
      "(16, 18)\n",
      "Minibatch loss at step 100: 4.264675\n",
      "Validation RMSE: 0.53872\n",
      "==================================\n",
      "Net finished training!\n"
     ]
    }
   ],
   "source": [
    "## ------------------------------------------------------------------------\n",
    "## Now we can use the TF graph\n",
    "## ------------------------------------------------------------------------\n",
    "print (\"Start running TF graph ... \")\n",
    "num_steps = 101\n",
    "\n",
    "train_acc_records = np.zeros(num_steps)\n",
    "valid_acc_records = np.zeros(num_steps)\n",
    "# test_acc_records = np.zeros(num_steps)\n",
    "loss_records = np.zeros(num_steps)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.Session(graph=deep_graph) as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    #tf.global_variables_initializer().run()\n",
    "    print (\"TF graph variables initialized ... \")\n",
    " \n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
    "\n",
    "        batch_data = x_train[offset:(offset + batch_size),:]\n",
    "        batch_labels = y_train[offset:(offset + batch_size)]\n",
    "        print (batch_labels.shape)\n",
    "        \n",
    "        feed_dict = {tf_train_dataset: batch_data,\n",
    "                     tf_train_labels: batch_labels}\n",
    "\n",
    "        _,l, pred = sess.run([optimizer, loss, train_prediction], feed_dict = feed_dict)\n",
    "\n",
    "        train_acc_records[step] = eval_error(pred, batch_labels)\n",
    "        valid_acc_records[step] = eval_error(valid_prediction.eval(), y_valid)\n",
    "#         test_acc_records[step] = eval_error(test_prediction.eval(), y_test)\n",
    "\n",
    "        if (step % 2) == 0:\n",
    "            print (\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "#             print (\"Minibatch RMSE: %0.5f\" % train_acc_records[step])\n",
    "            print (\"Validation RMSE: %0.5f\" % valid_acc_records[step])\n",
    "#             print (\"Test RMSE: %0.5f\" % test_acc_records[step])\n",
    "    time_elasped = time.time() - start_time\n",
    "    print (\"==================================\")\n",
    "    print (\"Net finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8e640a24d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAECCAYAAAD3vwBsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABIFAEAAIn6/8E7N97yXzpPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8edc09fb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.semilogy(train_acc_records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
